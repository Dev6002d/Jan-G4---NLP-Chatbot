{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('GL Bot.json') as file:\n",
    "    Corpus = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tflearn\n",
    "import random\n",
    "import pickle\n",
    "import numpy\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "import os\n",
    "from tkinter import filedialog\n",
    "\n",
    "FORMAT = \"utf-8\"\n",
    "import nltk\n",
    "\n",
    "text_contents=dict()\n",
    "nltk.download('punkt',quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer #word lemmatizer class\n",
    "lemma = WordNetLemmatizer()\n",
    "try:\n",
    "    with open(\"data.pickle1\", \"rb\") as f:\n",
    "        words, labels, training, output = pickle.load(f)\n",
    "except:\n",
    "    words = []\n",
    "    labels = []\n",
    "    docs_x = []\n",
    "    docs_y = []\n",
    "#  Fetching the words and tags from the corpus\n",
    "    for intent in Corpus[\"intents\"]:\n",
    "        for pattern in intent[\"patterns\"]:\n",
    "            wrds = nltk.word_tokenize(pattern)\n",
    "            words.extend(wrds)\n",
    "            docs_x.append(wrds)\n",
    "            docs_y.append(intent[\"tag\"])\n",
    "# print only one tag for all the pattern within that tag\n",
    "        if intent[\"tag\"] not in labels:\n",
    "            labels.append(intent[\"tag\"])\n",
    "# Stemming the word and convert in into lower case\n",
    "    words = [lemma.lemmatize(w.lower()) for w in words if w != \"?\"]\n",
    "    words = sorted(list(set(words)))\n",
    "\n",
    "    labels = sorted(labels)\n",
    "# Preparing Training and Output data\n",
    "    training = []\n",
    "    output = []\n",
    "\n",
    "    out_empty = [0 for _ in range(len(labels))]\n",
    "\n",
    "    for x, doc in enumerate(docs_x):\n",
    "        bag = []\n",
    "\n",
    "        wrds = [lemma.lemmatize(w.lower()) for w in doc]\n",
    "\n",
    "        for w in words:\n",
    "            if w in wrds:\n",
    "                bag.append(1)\n",
    "            else:\n",
    "                bag.append(0)\n",
    "\n",
    "        output_row = out_empty[:]\n",
    "        output_row[labels.index(docs_y[x])] = 1\n",
    "\n",
    "        training.append(bag)\n",
    "        output.append(output_row)\n",
    "\n",
    "\n",
    "    training = numpy.array(training)\n",
    "    output = numpy.array(output)\n",
    "\n",
    "    with open(\"data.pickle1\", \"wb\") as f:\n",
    "        pickle.dump((words, labels, training, output), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 15999  | time: 0.052s\n",
      "| Adam | epoch: 1000 | loss: 0.00000 - acc: 0.9247 -- iter: 120/128\n",
      "Training Step: 16000  | time: 0.060s\n",
      "| Adam | epoch: 1000 | loss: 0.00000 - acc: 0.9322 -- iter: 128/128\n",
      "--\n",
      "INFO:tensorflow:F:\\Great learning\\Capstone\\model.tflearn1 is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "\n",
    "net = tflearn.input_data(shape=[None, len(training[0])])\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, len(output[0]), activation=\"softmax\")\n",
    "net = tflearn.regression(net)\n",
    "\n",
    "model = tflearn.DNN(net)\n",
    "\n",
    "try:\n",
    "    model.load(\"model.tflearn1\")\n",
    "except:\n",
    "    model = tflearn.DNN(net)\n",
    "    model.fit(training, output, n_epoch=1000, batch_size=8, show_metric=True)\n",
    "    model.save(\"model.tflearn1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greet_res(text):\n",
    "    text=text.lower()\n",
    "    bot_greet=['hi','hello','hola','hey','howdy']\n",
    "    usr_greet=['hi','hey','hello','hola','greetings','wassup','whats up']\n",
    "    for word in text.split():\n",
    "        if word in usr_greet:\n",
    "            return random.choice(bot_greet)\n",
    "# bot response\n",
    "def bot_ress(usr_input):\n",
    "        usr_input = usr_input.lower()\n",
    "        bot_res = ''\n",
    "        results = model.predict([bag_of_words(usr_input, words)])\n",
    "        results_index = numpy.argmax(results)\n",
    "        tag = labels[results_index]\n",
    "\n",
    "        for tg in Corpus[\"intents\"]:\n",
    "            if tg['tag'] == tag:\n",
    "                responses = tg['responses']\n",
    "        bot_res = random.choice(responses)                \n",
    "        return bot_res\n",
    "\n",
    "def widget_get():\n",
    "    text_widget = root.nametowidget(textcon)\n",
    "    return text_widget.get('1.0','end-1c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveas(event=None):\n",
    "    global file_path,filename\n",
    "    file_path= filedialog.asksaveasfilename( defaultextension=\".txt\")\n",
    "    try:\n",
    "        filename=os.path.basename(file_path)\n",
    "        root.title(f\"Chat Bot - {filename}\")\n",
    "        content=widget_get()\n",
    "        with open(file_path ,\"w\") as file:\n",
    "            file.write(content)\n",
    "            text_contents[str(textcon)]=hash(content)\n",
    "            print(\"Operation successfull\")\n",
    "    except(FileNotFoundError):\n",
    "        print(\"Operation not successfull\")\n",
    "        return None\n",
    "file_path =None\n",
    "\n",
    "def save(event=None):\n",
    "    global file_path,filename\n",
    "    try:\n",
    "        if(file_path is None):\n",
    "            file_path = filedialog.asksaveasfilename(defaultextension=\".txt\")\n",
    "        filename=os.path.basename(file_path)\n",
    "        root.title(f\"Chat Bot - {filename}\")\n",
    "        content=widget_get()\n",
    "        with open(file_path ,\"w\") as file:\n",
    "            file.write(content)\n",
    "            text_contents[str(textcon)] = hash(content)\n",
    "            print(\"Operation successfull\")\n",
    "    except(FileNotFoundError):\n",
    "        print(\"Operation not successfull\")\n",
    "        return None\n",
    "\n",
    "def new(event=None):\n",
    "    textcon.delete('2.0', 'end-1c')\n",
    "    global  file_path,filename\n",
    "    file_path = None\n",
    "    content = widget_get()\n",
    "    text_contents[str(textcon)] = hash(content)\n",
    "    filename=None\n",
    "\n",
    "def clear(event=None):\n",
    "    textcon.delete('2.0', 'end-1c')\n",
    "    content = widget_get()\n",
    "    text_contents[str(textcon)] = hash(content)\n",
    "    \n",
    "def fopen(event=None):\n",
    "    global file_path,filename\n",
    "    file_path = filedialog.askopenfilename(defaultextension=\".txt\")\n",
    "    try:\n",
    "        filename = os.path.basename(file_path)\n",
    "        root.title(f\"Chat Bot - {filename}\")\n",
    "        text_widget = root.nametowidget(textcon)\n",
    "        with open(file_path, \"r\") as file:\n",
    "            content=file.read()\n",
    "            textcon.delete('1.0', 'end-1c')\n",
    "            text_contents[str(textcon)] = hash(content)\n",
    "            text_widget.insert(END,content)\n",
    "            print(\"Operation successfull\")\n",
    "    except(FileNotFoundError):\n",
    "        print(\"Operation not successfull\")\n",
    "        return None\n",
    "\n",
    "exit_list = ['exit','break','quit','see you later','chat with you later','end the chat','bye','ok bye']\n",
    "\n",
    "def send(event=None):\n",
    "    usr_input = message.get()\n",
    "    usr_input = usr_input.lower()\n",
    "    textcon.insert(END, f'User: {usr_input}'+'\\n','usr')\n",
    "    if usr_input in exit_list:\n",
    "        textcon.config(fg='Yellow')\n",
    "        textcon.insert(END,\"Bot:Ok bye! Chat with you later\\n\")\n",
    "        return root.destroy()\n",
    "    else:\n",
    "        textcon.config(fg='yellow')\n",
    "        if greet_res(usr_input) != None:\n",
    "            lab=f\"Bot: {greet_res(usr_input)}\"+'\\n'\n",
    "            textcon.insert(END,lab)\n",
    "            mes_win.delete(0,END)\n",
    "        else:\n",
    "            lab = f\"Bot: {bot_ress(usr_input)}\"+'\\n'\n",
    "            textcon.insert(END, lab)\n",
    "            mes_win.delete(0,END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(s, words):\n",
    "    bag = [0 for _ in range(len(words))]\n",
    "\n",
    "    s_words = nltk.word_tokenize(s)\n",
    "    s_words = [lemma.lemmatize(word.lower()) for word in s_words]\n",
    "\n",
    "    for se in s_words:\n",
    "        for i, w in enumerate(words):\n",
    "            if w == se:\n",
    "                bag[i] = 1\n",
    "            \n",
    "    return numpy.array(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "root=tk.Tk()\n",
    "filename=\"Untitled.txt\"\n",
    "root.title(f\"Chat Bot - Untitled.txt\")\n",
    "root.geometry('500x400')\n",
    "\n",
    "root.resizable(False, False)\n",
    "main_menu=Menu(root)\n",
    "file_menu=Menu(root)\n",
    "file_menu.add_command(label='Open  <Ctrl+O>',command=fopen)\n",
    "file_menu.add_command(label='New  <Ctrl+N>',command=new)\n",
    "file_menu.add_command(label='Save  <Ctrl+S>',command=save)\n",
    "file_menu.add_command(label='Save as <Ctrl+Shift+S>',command=saveas)\n",
    "edit_menu=Menu(root)\n",
    "edit_menu.add_command(label='Clear  <Delete>',command=clear)\n",
    "main_menu.add_cascade(label=\"File\",menu=file_menu)\n",
    "main_menu.add_cascade(label=\"Edit\",menu=edit_menu)\n",
    "main_menu.add_command(label=\"Quit\",command=root.destroy)\n",
    "root.config(menu=main_menu)\n",
    "\n",
    "message=tk.StringVar()\n",
    "chat_win=Frame(root,bd=1,bg='black',width=50,height=8)\n",
    "chat_win.place(x=6,y=6,height=300,width=480)\n",
    "\n",
    "textcon=tk.Text(chat_win,bd=1,bg='black',width=50,height=8)\n",
    "textcon.pack(fill=\"both\",expand=True)\n",
    "\n",
    "mes_win=Entry(root,width=30,xscrollcommand=True,textvariable=message)\n",
    "mes_win.place(x=6,y=310,height=60,width=366)\n",
    "mes_win.focus()\n",
    "\n",
    "textcon.config(fg='yellow')\n",
    "textcon.tag_config('usr',foreground='white')\n",
    "textcon.insert(END,\"Bot: This is Jarvis to assist you in Industrial safety!\\n\\n\")\n",
    "mssg=mes_win.get()\n",
    "\n",
    "button=Button(root,text='Send',bg='grey',activebackground='orange',command=send,width=12,height=5,font=('Arial'))\n",
    "button.place(x=376,y=310,height=60,width=110)\n",
    "\n",
    "scrollbar=tk.Scrollbar(textcon)\n",
    "scrollbar.pack(fill='y')\n",
    "scrollbar.place(relheight = 1,relx = 1)\n",
    "scrollbar.config(command = textcon.yview)\n",
    "\n",
    "content = widget_get()\n",
    "text_contents[str(textcon)] = hash(content)\n",
    "root.bind('<Control-s>',save,file_menu)\n",
    "root.bind('<Control-Shift-s>',saveas,file_menu)\n",
    "root.bind('<Return>', send,button)\n",
    "root.bind('<Control-n>', new,file_menu)\n",
    "root.bind('<Delete>', clear,edit_menu)\n",
    "root.bind('<Control-o>', fopen,file_menu)\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
