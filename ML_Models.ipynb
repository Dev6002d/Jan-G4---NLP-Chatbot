{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Capstone_NLP_Chatbot_Jan_A_G4_15_12.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shyamsparrow/Jan-G4---NLP-Chatbot/blob/Models/ML_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Yj3kJll4cxT"
      },
      "source": [
        "# Capstone Project - NLP Chatbot\n",
        "\n",
        "### DOMAIN: \n",
        "Industrial safety. NLP based Chatbot.\n",
        "\n",
        "### CONTEXT:\n",
        "The database comes from one of the biggest industry in Brazil and in the world. It is an urgent need for industries/companies around the globe to understand why employees still suffer some injuries/accidents in plants. Sometimes they also die in such environment.\n",
        "\n",
        "### DATA DESCRIPTION:\n",
        "This The database is basically records of accidents from 12 different plants in 03 different countries which every line in the data is an occurrence of an accident.\n",
        "\n",
        "### Columns description:\n",
        "* Data: timestamp or time/date information\n",
        "* Countries: which country the accident occurred (anonymised)\n",
        "* Local: the city where the manufacturing plant is located (anonymised)\n",
        "* Industry sector: which sector the plant belongs to\n",
        "* Accident level: from I to VI, it registers how severe was the accident (I means not severe but VI means very severe)\n",
        "* Potential Accident Level: Depending on the Accident Level, the database also registers how severe the accident could have   been (due to other factors involved in the accident)\n",
        "* Gender: if the person is male of female\n",
        "* Employee or Third Party: if the injured person is an employee or a third party\n",
        "* Critical Risk: some description of the risk involved in the accident\n",
        "* Description: Detailed description of how the accident happened.\n",
        "\n",
        "Link to download the dataset: https://drive.google.com/file/d/1_GmrRP1S2OIa02KlfOBNkYa8uxazGbfE/view?usp=sharing,\n",
        "Original dataset link: https://www.kaggle.com/ihmstefanini/industrial-safety-and-health-analytics-database\n",
        "\n",
        "### PROJECT OBJECTIVE:\n",
        "Design a ML/DL based chatbot utility which can help the professionals to highlight the safety risk as per the incident description."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXY9aXj-FwOg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc53d68e-4f0f-44b2-a5ae-342d86a354c5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJ3cY1PPaSlS"
      },
      "source": [
        "Replace the folder path with your drive folder path and clone the githb repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwhw9SyePdXo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a61fa85-1040-494b-dd45-d36138bb16db"
      },
      "source": [
        "%cd /content/drive/MyDrive/AIML/Capstone"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/AIML/Capstone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zb2bSd4Qa6sd"
      },
      "source": [
        "Run the below code for clone the repo in our Googele drive for first time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02mIR5BkLrQM",
        "outputId": "a1ed0f00-4726-4614-bde1-ae0ecc1e73df"
      },
      "source": [
        "! git clone https://github.com/shyamsparrow/Jan-G4---NLP-Chatbot.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Jan-G4---NLP-Chatbot' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DE4JYNESXKDx"
      },
      "source": [
        "Change the Current folder into Github repo main folder, all the functions we are calling has to be in this repo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OigsCtatbCvx",
        "outputId": "f5fd2006-034c-44f3-8e11-8d66fbfbb426"
      },
      "source": [
        "%cd /content/drive/MyDrive/AIML/Capstone/Jan-G4---NLP-Chatbot"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/AIML/Capstone/Jan-G4---NLP-Chatbot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DP36cGdeCGy"
      },
      "source": [
        "!git config --global user.email \"pradeebha.ab@gmail.com\"\n",
        "!git config --global user.name \"Pradeebha\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dduXV2HWejMI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c0bf1c3-6faa-4ac7-ac33-ddf61ac3c0c2"
      },
      "source": [
        "!git status"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\n",
            "\t\u001b[31m__pycache__/\u001b[m\n",
            "\n",
            "nothing added to commit but untracked files present (use \"git add\" to track)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mdx1iSzven86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acc37aa3-d023-4f18-9dba-672d9e6bdb2b"
      },
      "source": [
        "!git commit -m \"My message\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: cannot lock ref 'HEAD': Unable to create '/content/drive/My Drive/AIML/Capstone/Jan-G4---NLP-Chatbot/.git/refs/heads/main\n",
            "r.lock': Invalid argument\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuZqYC2yXV1e"
      },
      "source": [
        "Run this code to update the changes in repo to our drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WITqKl1Nb_G4",
        "outputId": "19804832-f91d-4dc0-f984-98c73421d73e"
      },
      "source": [
        "!git pull"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 38, done.\u001b[K\n",
            "remote: Counting objects: 100% (38/38), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 34 (delta 15), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (34/34), done.\n",
            "From https://github.com/shyamsparrow/Jan-G4---NLP-Chatbot\n",
            " * [new branch]      CNN_LSTM_Ganesh -> origin/CNN_LSTM_Ganesh\n",
            "   08de628..49c4cce  Models          -> origin/Models\n",
            " * [new branch]      Simple_Transformer_Model -> origin/Simple_Transformer_Model\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4CkHgK24cxV"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, recall_score, precision_score, roc_auc_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pickle\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5sQ-rKcCO5i"
      },
      "source": [
        "industry_df = pd.read_csv(\"/content/drive/MyDrive/AIML/Capstone/Jan-G4---NLP-Chatbot/industry_df_preprocessed.csv\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TGiZyni0VDM"
      },
      "source": [
        "Model Building: Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWJygL6Cz0ea"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(industry_df['Description_preprocessed'], industry_df['Potential_Accident_Level'].values, test_size=0.2, random_state=42)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XURiVVJ0yxz",
        "outputId": "86144c98-000f-4912-e774-88e2c6c5e712"
      },
      "source": [
        "print('Training utterances: {}'.format(X_train.shape[0]))\n",
        "print('Validation utterances: {}'.format(X_test.shape[0]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training utterances: 328\n",
            "Validation utterances: 83\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oED_mhDp0zEP"
      },
      "source": [
        "# Defining a function which quickly test the fit of 6 different models on the dataset\n",
        "def ml_models(X_train , y_train, X_test, y_test):\n",
        "\n",
        "    # creating a dictionary with different ML models\n",
        "    models = {\n",
        "        'LogReg': LogisticRegression(), \n",
        "        'Naive Bayes': GaussianNB(),        \n",
        "        'KNN': KNeighborsClassifier(),\n",
        "        'SVM': SVC(), \n",
        "        'Decision Tree': DecisionTreeClassifier(criterion='entropy',max_depth=6,random_state=100,min_samples_leaf=5),          \n",
        "        'RandomForest': RandomForestClassifier(n_estimators=100, max_depth=7),\n",
        "        'Bagging': BaggingClassifier(n_estimators=50, max_samples=.7),\n",
        "        'AdaBoost': AdaBoostClassifier(n_estimators= 50),\n",
        "        'Gradient Boost': GradientBoostingClassifier(n_estimators = 50, learning_rate = 0.05),\n",
        "        'XGBoost': XGBClassifier()\n",
        "    }\n",
        "    \n",
        "    names = []\n",
        "    scores = []\n",
        "\n",
        "    for name, model in models.items(): # Looping through each and every model\n",
        "        clf = model.fit(X_train, y_train) # Fit the models one by one\n",
        "        result = clf.score(X_test,y_test) \n",
        "\n",
        "        names.append(name)\n",
        "        scores.append(result) # Appending the test scores to the list\n",
        "\n",
        "        result_df =  pd.DataFrame({'model': names, 'accuracy': scores}) # Creating the dataframe using the model scores\n",
        "      \n",
        "    return result_df # Returns the dataframe"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0zbvYav1LHl"
      },
      "source": [
        "TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHFRB36R1NFn"
      },
      "source": [
        "TF-IDF is a statistical measure that evaluates how relevant a word is to a document in a collection of documents. This is done by multiplying two metrics: how many times a word appears in a document, and the inverse document frequency of the word across a set of documents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTJ_LjJV1cQh"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzLPJnPC0zHJ"
      },
      "source": [
        "# Initializing TfidfVectorizer object\n",
        "tfIdfVectorizer = TfidfVectorizer()\n",
        "X_train_tf = tfIdfVectorizer.fit_transform(X_train)\n",
        "X_test_tf = tfIdfVectorizer.transform(X_test)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tf[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zuDGox5OuiuW",
        "outputId": "b1e31682-18eb-4f32-8e68-c564ed42377b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1x2671 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 54 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLjLm_qj1jAb"
      },
      "source": [
        "ML Classifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_EmE7W60zKG"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "T49cy1Br0zM0",
        "outputId": "9177d92a-e7cb-45b0-fda9-924ef77264f8"
      },
      "source": [
        "ml_models(X_train_tf.toarray(), y_train, X_test_tf.toarray(), y_test)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogReg</td>\n",
              "      <td>0.373494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.421687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>KNN</td>\n",
              "      <td>0.361446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SVM</td>\n",
              "      <td>0.361446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>0.313253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>RandomForest</td>\n",
              "      <td>0.373494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Bagging</td>\n",
              "      <td>0.337349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>AdaBoost</td>\n",
              "      <td>0.349398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Gradient Boost</td>\n",
              "      <td>0.325301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.313253</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            model  accuracy\n",
              "0          LogReg  0.373494\n",
              "1     Naive Bayes  0.421687\n",
              "2             KNN  0.361446\n",
              "3             SVM  0.361446\n",
              "4   Decision Tree  0.313253\n",
              "5    RandomForest  0.373494\n",
              "6         Bagging  0.337349\n",
              "7        AdaBoost  0.349398\n",
              "8  Gradient Boost  0.325301\n",
              "9         XGBoost  0.313253"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUUs_s-j2iUg"
      },
      "source": [
        "For TF-IDF vectorization, the accuracy is quite less. Though Logistic Regression performs better than the rest, The accuracy is not upto the mark. Next better accuracy comes with Naive Bayes clasifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F66cB89v3Fkv"
      },
      "source": [
        "Using Bag of words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEsqL8I13IM7"
      },
      "source": [
        "A bag-of-words is a representation of text that describes the occurrence of words within a document."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFANiquS0zPf"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFhmXOgO0zR7"
      },
      "source": [
        "vectorizer = CountVectorizer(binary=True, ngram_range=(1, 2))\n",
        "X_train_bow = vectorizer.fit_transform(X_train)\n",
        "X_test_bow = vectorizer.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jk2uPT93bDy"
      },
      "source": [
        "ML Classifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "Bb93wOOI3WSr",
        "outputId": "cda75672-e525-4d7a-93e2-4356197ea570"
      },
      "source": [
        "ml_models(X_train_bow.toarray(), y_train, X_test_bow.toarray(), y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogReg</td>\n",
              "      <td>0.433735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.421687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>KNN</td>\n",
              "      <td>0.265060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SVM</td>\n",
              "      <td>0.349398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>0.313253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>RandomForest</td>\n",
              "      <td>0.349398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Bagging</td>\n",
              "      <td>0.373494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>AdaBoost</td>\n",
              "      <td>0.349398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Gradient Boost</td>\n",
              "      <td>0.337349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.409639</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            model  accuracy\n",
              "0          LogReg  0.433735\n",
              "1     Naive Bayes  0.421687\n",
              "2             KNN  0.265060\n",
              "3             SVM  0.349398\n",
              "4   Decision Tree  0.313253\n",
              "5    RandomForest  0.349398\n",
              "6         Bagging  0.373494\n",
              "7        AdaBoost  0.349398\n",
              "8  Gradient Boost  0.337349\n",
              "9         XGBoost  0.409639"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IS3ucWe14DNw"
      },
      "source": [
        "The accuracy using BOW is more or less similar to those we got using TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter Tuning:"
      ],
      "metadata": {
        "id": "l8NzH2RkmPmn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RepeatedStratifiedKFold"
      ],
      "metadata": {
        "id": "_v7EYzqCp2ry"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
      ],
      "metadata": {
        "id": "nDRTeAJ5p-zG"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hyperparameterstune_model(name, model, X_train, y_train, param_grid):\n",
        "    \n",
        "    #start = time.time()  # note the start time \n",
        "    \n",
        "    # Before starting with grid search we need to create a scoring function. This is accomplished using the make_scorer function of scikit-learn.\n",
        "    # mll_scorer = metrics.make_scorer(multiclass_logloss, greater_is_better=False, needs_proba=True)\n",
        "\n",
        "    # define grid search\n",
        "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "    if name == 'LGBMClassifier':\n",
        "      grid_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=100, n_jobs=-1, cv=cv, \n",
        "                                        error_score=0)\n",
        "    else:\n",
        "      grid_search = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=cv, \n",
        "                                  error_score=0)\n",
        "      \n",
        "    model_grid_result = grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # summarize results\n",
        "    print(\"Best F1_Score: %f using %s\" % (model_grid_result.best_score_, model_grid_result.best_params_))\n",
        "    means = model_grid_result.cv_results_['mean_test_score']\n",
        "    stds = model_grid_result.cv_results_['std_test_score']\n",
        "    params = model_grid_result.cv_results_['params']\n",
        "    for mean, stdev, param in zip(means, stds, params):\n",
        "      if param == model_grid_result.best_params_:\n",
        "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
        "        print(\"95% Confidence interval range: ({0:.4f} %, {1:.4f} %)\".format(mean-(2*stdev), mean+(2*stdev)))\n",
        "\n",
        "    #end = time.time()  # note the end time\n",
        "    #duration = end - start  # calculate the total duration\n",
        "    #print(\"Total duration\" , duration, \"\\n\")\n",
        "    \n",
        "    return model_grid_result.best_estimator_"
      ],
      "metadata": {
        "id": "Q9UTS2hCmUkn"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define regressor models\n",
        "models=[['LogisticRegression',LogisticRegression()],\n",
        "    \n",
        "    ['KNeighborsClassifier',KNeighborsClassifier()],\n",
        " \n",
        "    ['RandomForestClassifier',RandomForestClassifier()],\n",
        "    ['BaggingClassifier',BaggingClassifier()],\n",
        "    \n",
        "    ['AdaBoostClassifier',AdaBoostClassifier()],\n",
        "    ['GradientBoostingClassifier',GradientBoostingClassifier()],\n",
        "    \n",
        "    ['XGBClassifier',XGBClassifier()]\n",
        "]\n",
        "\n",
        "# define model parameters\n",
        "\n",
        "lr_param_grid = {'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
        "                 'penalty': ['l2'],\n",
        "                 #'penalty': ['none', 'l1', 'l2', 'elasticnet'],\n",
        "                 'C': [100, 10, 1.0, 0.1, 0.01]}\n",
        "                 #'class_weight':['none','balanced'],\n",
        "                 #'multi_class':['ovr', 'multinomial']}\n",
        "\n",
        "knn_param_grid = {'n_neighbors': range(3, 21, 2),\n",
        "                 'weights': ['uniform', 'distance'],\n",
        "                 'metric': ['euclidean', 'manhattan', 'minkowski']}\n",
        "\n",
        "rf_param_grid = {'n_estimators': [10, 100, 1000],\n",
        "                 'max_features': ['auto', 'sqrt', 'log2']}              \n",
        "                 #'class_weight':['balanced','balanced_subsample','none']}\n",
        "bag_param_grid = {'n_estimators': [10, 100, 1000],\n",
        "                 'max_samples': np.arange(0.7, 0.8, 0.05)}\n",
        "\n",
        "adb_param_grid = {'n_estimators': np.arange(30,100,10),\n",
        "                 'learning_rate': np.arange(0.1,1,0.5)}\n",
        "gb_param_grid = {'n_estimators': [10, 50, 100, 500],\n",
        "                 'learning_rate': [0.0001, 0.001, 0.01, 0.1, 1.0],\n",
        "                 'subsample':[0.5, 0.7, 1.0],\n",
        "                 'max_depth': [3, 7, 9]}\n",
        "\n",
        "                \n",
        "xgb_param_grid = {'learning_rate': [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ],\n",
        "                  'max_depth' : [3, 4, 5, 6, 8, 10, 12, 15],\n",
        "                  'min_child_weight': [ 1, 3, 5, 7],\n",
        "                  'gamma': [0.0, 0.1, 0.2 , 0.3, 0.4],\n",
        "                  'colsample_bytree': [ 0.3, 0.4, 0.5 , 0.7],\n",
        "                  'objective': ['multi:softmax'],\n",
        "                  'eval_metric': ['mlogloss'],\n",
        "                  'num_class': [5]}\n",
        "\n",
        "for name, classifier in models:\n",
        "    if name == 'LogisticRegression':\n",
        "        lr_best_estimator = hyperparameterstune_model(name, classifier, X_train_tf, y_train, lr_param_grid)\n",
        "    \n",
        "    elif name == 'KNeighborsClassifier':\n",
        "        knn_best_estimator = hyperparameterstune_model(name, classifier, X_train_tf, y_train, knn_param_grid)\n",
        "   \n",
        "    elif name == 'RandomForestClassifier':\n",
        "        rf_best_estimator = hyperparameterstune_model(name, classifier, X_train_tf, y_train, rf_param_grid)\n",
        "    \n",
        "    elif name == 'AdaBoostClassifier':\n",
        "        adb_best_estimator = hyperparameterstune_model(name, classifier, X_train_tf, y_train, adb_param_grid)\n",
        "    elif name == 'GradientBoostingClassifier':\n",
        "        gb_best_estimator = hyperparameterstune_model(name, classifier, X_train_tf, y_train, gb_param_grid)\n",
        "    \n",
        "    elif name == 'XGBClassifier':\n",
        "        xgb_best_estimator = hyperparameterstune_model(name, classifier, X_train_tf, y_train, xgb_param_grid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeX6KM8mmUnv",
        "outputId": "c42c4055-34a3-4ff8-dc7c-877059c23bd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best F1_Score: 0.432765 using {'C': 10, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.432765 (0.071872) with: {'C': 10, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "95% Confidence interval range: (0.2890 %, 0.5765 %)\n",
            "Best F1_Score: 0.465372 using {'metric': 'euclidean', 'n_neighbors': 9, 'weights': 'distance'}\n",
            "0.465372 (0.069197) with: {'metric': 'euclidean', 'n_neighbors': 9, 'weights': 'distance'}\n",
            "95% Confidence interval range: (0.3270 %, 0.6038 %)\n",
            "Best F1_Score: 0.454293 using {'max_features': 'sqrt', 'n_estimators': 1000}\n",
            "0.454293 (0.067960) with: {'max_features': 'sqrt', 'n_estimators': 1000}\n",
            "95% Confidence interval range: (0.3184 %, 0.5902 %)\n",
            "Best F1_Score: 0.379104 using {'learning_rate': 0.1, 'n_estimators': 30}\n",
            "0.379104 (0.047055) with: {'learning_rate': 0.1, 'n_estimators': 30}\n",
            "95% Confidence interval range: (0.2850 %, 0.4732 %)\n"
          ]
        }
      ]
    }
  ]
}